augment2d:
  gridmask:
    fixed_prob: true
    prob: 0.0
  resize:
  - - 0.38
    - 0.55
  - - 0.48
    - 0.48
  rotate:
  - -5.4
  - 5.4
augment3d:
  rotate:
  - -0.78539816
  - 0.78539816
  scale:
  - 0.9
  - 1.1
  translate: 0.5
checkpoint_config:
  interval: 1
  max_keep_ckpts: 1
cudnn_benchmark: false
data:
  samples_per_gpu: 2
  test:
    ann_file: ${dataset_root + "nuscenes_infos_val.pkl"}
    box_type_3d: LiDAR
    dataset_root: ${dataset_root}
    map_classes: ${map_classes}
    modality: ${input_modality}
    object_classes: ${object_classes}
    pipeline: ${test_pipeline}
    test_mode: true
    type: ${dataset_type}
  train:
    dataset:
      ann_file: ${dataset_root + "nuscenes_infos_train.pkl"}
      box_type_3d: LiDAR
      dataset_root: ${dataset_root}
      map_classes: ${map_classes}
      modality: ${input_modality}
      object_classes: ${object_classes}
      pipeline: ${train_pipeline}
      test_mode: false
      type: ${dataset_type}
      use_valid_flag: true
    type: CBGSDataset
  val:
    ann_file: ${dataset_root + "nuscenes_infos_val.pkl"}
    box_type_3d: LiDAR
    dataset_root: ${dataset_root}
    map_classes: ${map_classes}
    modality: ${input_modality}
    object_classes: ${object_classes}
    pipeline: ${test_pipeline}
    test_mode: false
    type: ${dataset_type}
  workers_per_gpu: 2
dataset_root: data/nuscenes/
dataset_type: NuScenesDataset
deterministic: false
evaluation:
  interval: 1
  pipeline: ${test_pipeline}
fp16:
  loss_scale:
    growth_interval: 2000
gt_paste_stop_epoch: -1
image_size:
- 256
- 704
input_modality:
  use_camera: true
  use_external: false
  use_lidar: true
  use_map: false
  use_radar: false
load_augmented: null
load_dim: 5
load_from: pretrained/lidar-only-det.pth
log_config:
  hooks:
  - type: TextLoggerHook
  - type: TensorboardLoggerHook
  interval: 50
lr_config:
  min_lr_ratio: 0.001
  policy: CosineAnnealing
  warmup: linear
  warmup_iters: 61790
  warmup_ratio: 0.33333333
map_classes:
- drivable_area
- ped_crossing
- walkway
- stop_line
- carpark_area
- divider
max_epochs: 6
model:
  decoder:
    backbone:
      conv_cfg:
        bias: false
        type: Conv2d
      in_channels: 256
      layer_nums:
      - 5
      - 5
      layer_strides:
      - 1
      - 2
      norm_cfg:
        eps: 0.001
        momentum: 0.01
        type: BN
      out_channels:
      - 128
      - 256
      type: SECOND
    neck:
      in_channels:
      - 128
      - 256
      norm_cfg:
        eps: 0.001
        momentum: 0.01
        type: BN
      out_channels:
      - 256
      - 256
      type: SECONDFPN
      upsample_cfg:
        bias: false
        type: deconv
      upsample_strides:
      - 1
      - 2
      use_conv_for_no_stride: true
  encoders:
    camera:
      backbone:
        depth: 50
        # layers:
        # - 4
        # - 4
        # - 6 
        # - 4
        # pretrained: '/root/once-for-all/subnets/subnet_4464.pth'
        init_cfg:
          checkpoint: https://download.pytorch.org/models/resnet50-0676ba61.pth
          type: Pretrained
        out_indices:
        - 1
        - 2
        - 3
        type: ResNet
        # type: CustomResNet
      neck:
        act_cfg:
          inplace: true
          type: ReLU
        in_channels:
        - 512
        - 1024
        - 2048
        norm_cfg:
          requires_grad: true
          type: BN2d
        num_outs: 3
        out_channels: 256
        start_level: 0
        type: GeneralizedLSSFPN
        upsample_cfg:
          align_corners: false
          mode: bilinear
      vtransform:
        dbound:
        - 1.0
        - 60.0
        - 0.5
        downsample: 2
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]}
        image_size: ${image_size}
        in_channels: 256
        out_channels: 80
        type: DepthLSSTransform
        xbound:
        - -54.0
        - 54.0
        - 0.3
        ybound:
        - -54.0
        - 54.0
        - 0.3
        zbound:
        - -10.0
        - 10.0
        - 20.0
    lidar:
      backbone:
        block_type: basicblock
        encoder_channels:
        - - 16
          - 16
          - 32
        - - 32
          - 32
          - 64
        - - 64
          - 64
          - 128
        - - 128
          - 128
        encoder_paddings:
        - - 0
          - 0
          - 1
        - - 0
          - 0
          - 1
        - - 0
          - 0
          - - 1
            - 1
            - 0
        - - 0
          - 0
        in_channels: 5
        order:
        - conv
        - norm
        - act
        output_channels: 128
        sparse_shape:
        - 1440
        - 1440
        - 41
        type: SparseEncoder
      voxelize:
        max_num_points: 10
        max_voxels:
        - 120000
        - 160000
        point_cloud_range: ${point_cloud_range}
        voxel_size: ${voxel_size}
  fuser:
    in_channels:
    - 80
    - 256
    out_channels: 256
    type: ConvFuser
  heads:
    map: null
    object:
      activation: relu
      auxiliary: true
      bbox_coder:
        code_size: 10
        out_size_factor: 8
        pc_range: ${point_cloud_range[:2]}
        post_center_range:
        - -61.2
        - -61.2
        - -10.0
        - 61.2
        - 61.2
        - 10.0
        score_threshold: 0.0
        type: TransFusionBBoxCoder
        voxel_size: ${voxel_size[:2]}
      bn_momentum: 0.1
      common_heads:
        center:
        - 2
        - 2
        dim:
        - 3
        - 2
        height:
        - 1
        - 2
        rot:
        - 2
        - 2
        vel:
        - 2
        - 2
      dropout: 0.1
      ffn_channel: 256
      hidden_channel: 128
      in_channels: 512
      loss_bbox:
        loss_weight: 0.25
        reduction: mean
        type: L1Loss
      loss_cls:
        alpha: 0.25
        gamma: 2.0
        loss_weight: 1.0
        reduction: mean
        type: FocalLoss
        use_sigmoid: true
      loss_heatmap:
        loss_weight: 1.0
        reduction: mean
        type: GaussianFocalLoss
      nms_kernel_size: 3
      num_classes: 10
      num_decoder_layers: 1
      num_heads: 8
      num_proposals: 200
      test_cfg:
        dataset: nuScenes
        grid_size:
        - 1440
        - 1440
        - 41
        nms_type: null
        out_size_factor: 8
        pc_range: ${point_cloud_range[:2]}
        voxel_size: ${voxel_size[:2]}
      train_cfg:
        assigner:
          cls_cost:
            alpha: 0.25
            gamma: 2.0
            type: FocalLossCost
            weight: 0.15
          iou_calculator:
            coordinate: lidar
            type: BboxOverlaps3D
          iou_cost:
            type: IoU3DCost
            weight: 0.25
          reg_cost:
            type: BBoxBEVL1Cost
            weight: 0.25
          type: HungarianAssigner3D
        code_weights:
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 0.2
        - 0.2
        dataset: nuScenes
        gaussian_overlap: 0.1
        grid_size:
        - 1440
        - 1440
        - 41
        min_radius: 2
        out_size_factor: 8
        point_cloud_range: ${point_cloud_range}
        pos_weight: -1
        voxel_size: ${voxel_size}
      type: TransFusionHead
  type: BEVFusion
momentum_config:
  policy: cyclic
object_classes:
- car
- truck
- construction_vehicle
- bus
- trailer
- barrier
- motorcycle
- bicycle
- pedestrian
- traffic_cone
optimizer:
  lr: 1.0e-05
  type: AdamW
  weight_decay: 0.01
optimizer_config:
  grad_clip:
    max_norm: 35
    norm_type: 2
point_cloud_range:
- -54.0
- -54.0
- -5.0
- 54.0
- 54.0
- 3.0
reduce_beams: 32
resume_from: null
runner:
  max_epochs: ${max_epochs}
  type: CustomEpochBasedRunner
seed: 0
test_pipeline:
- to_float32: true
  type: LoadMultiViewImageFromFiles
- coord_type: LIDAR
  load_augmented: ${load_augmented}
  load_dim: ${load_dim}
  reduce_beams: ${reduce_beams}
  type: LoadPointsFromFile
  use_dim: ${use_dim}
- load_augmented: ${load_augmented}
  load_dim: ${load_dim}
  pad_empty_sweeps: true
  reduce_beams: ${reduce_beams}
  remove_close: true
  sweeps_num: 9
  type: LoadPointsFromMultiSweeps
  use_dim: ${use_dim}
- type: LoadAnnotations3D
  with_attr_label: false
  with_bbox_3d: true
  with_label_3d: true
- bot_pct_lim:
  - 0.0
  - 0.0
  final_dim: ${image_size}
  is_train: false
  rand_flip: false
  resize_lim: ${augment2d.resize[1]}
  rot_lim:
  - 0.0
  - 0.0
  type: ImageAug3D
- is_train: false
  resize_lim:
  - 1.0
  - 1.0
  rot_lim:
  - 0.0
  - 0.0
  trans_lim: 0.0
  type: GlobalRotScaleTrans
- classes: ${map_classes}
  dataset_root: ${dataset_root}
  type: LoadBEVSegmentation
  xbound:
  - -50.0
  - 50.0
  - 0.5
  ybound:
  - -50.0
  - 50.0
  - 0.5
- point_cloud_range: ${point_cloud_range}
  type: PointsRangeFilter
- mean:
  - 0.485
  - 0.456
  - 0.406
  std:
  - 0.229
  - 0.224
  - 0.225
  type: ImageNormalize
- classes: ${object_classes}
  type: DefaultFormatBundle3D
- keys:
  - img
  - points
  - gt_bboxes_3d
  - gt_labels_3d
  - gt_masks_bev
  meta_keys:
  - camera_intrinsics
  - camera2ego
  - lidar2ego
  - lidar2camera
  - camera2lidar
  - lidar2image
  - img_aug_matrix
  - lidar_aug_matrix
  type: Collect3D
train_pipeline:
- to_float32: true
  type: LoadMultiViewImageFromFiles
- coord_type: LIDAR
  load_augmented: ${load_augmented}
  load_dim: ${load_dim}
  reduce_beams: ${reduce_beams}
  type: LoadPointsFromFile
  use_dim: ${use_dim}
- load_augmented: ${load_augmented}
  load_dim: ${load_dim}
  pad_empty_sweeps: true
  reduce_beams: ${reduce_beams}
  remove_close: true
  sweeps_num: 9
  type: LoadPointsFromMultiSweeps
  use_dim: ${use_dim}
- type: LoadAnnotations3D
  with_attr_label: false
  with_bbox_3d: true
  with_label_3d: true
- db_sampler:
    classes: ${object_classes}
    dataset_root: ${dataset_root}
    info_path: ${dataset_root + "nuscenes_dbinfos_train.pkl"}
    points_loader:
      coord_type: LIDAR
      load_dim: ${load_dim}
      reduce_beams: ${reduce_beams}
      type: LoadPointsFromFile
      use_dim: ${use_dim}
    prepare:
      filter_by_difficulty:
      - -1
      filter_by_min_points:
        barrier: 5
        bicycle: 5
        bus: 5
        car: 5
        construction_vehicle: 5
        motorcycle: 5
        pedestrian: 5
        traffic_cone: 5
        trailer: 5
        truck: 5
    rate: 1.0
    sample_groups:
      barrier: 2
      bicycle: 6
      bus: 4
      car: 2
      construction_vehicle: 7
      motorcycle: 6
      pedestrian: 2
      traffic_cone: 2
      trailer: 6
      truck: 3
  stop_epoch: ${gt_paste_stop_epoch}
  type: ObjectPaste
- bot_pct_lim:
  - 0.0
  - 0.0
  final_dim: ${image_size}
  is_train: true
  rand_flip: true
  resize_lim: ${augment2d.resize[0]}
  rot_lim: ${augment2d.rotate}
  type: ImageAug3D
- is_train: true
  resize_lim: ${augment3d.scale}
  rot_lim: ${augment3d.rotate}
  trans_lim: ${augment3d.translate}
  type: GlobalRotScaleTrans
- classes: ${map_classes}
  dataset_root: ${dataset_root}
  type: LoadBEVSegmentation
  xbound:
  - -50.0
  - 50.0
  - 0.5
  ybound:
  - -50.0
  - 50.0
  - 0.5
- type: RandomFlip3D
- point_cloud_range: ${point_cloud_range}
  type: PointsRangeFilter
- point_cloud_range: ${point_cloud_range}
  type: ObjectRangeFilter
- classes: ${object_classes}
  type: ObjectNameFilter
- mean:
  - 0.485
  - 0.456
  - 0.406
  std:
  - 0.229
  - 0.224
  - 0.225
  type: ImageNormalize
- fixed_prob: ${augment2d.gridmask.fixed_prob}
  max_epoch: ${max_epochs}
  mode: 1
  offset: false
  prob: ${augment2d.gridmask.prob}
  ratio: 0.5
  rotate: 1
  type: GridMask
  use_h: true
  use_w: true
- type: PointShuffle
- classes: ${object_classes}
  type: DefaultFormatBundle3D
- keys:
  - img
  - points
  - gt_bboxes_3d
  - gt_labels_3d
  - gt_masks_bev
  meta_keys:
  - camera_intrinsics
  - camera2ego
  - lidar2ego
  - lidar2camera
  - camera2lidar
  - lidar2image
  - img_aug_matrix
  - lidar_aug_matrix
  type: Collect3D
use_dim: 5
voxel_size:
- 0.075
- 0.075
- 0.2
